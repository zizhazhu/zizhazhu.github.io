---
title: 深度学习 第六章 深度前馈网络
date: 2019-05-07 17:22:46
mathjax: true
categories:
- Computer
- Deep Learning
- Deep Learning Book
tags:
- Notes
- Deep Learning

---

前馈网络的目标是近似某个函数$f^*$。前馈网络定义了一个映射$y=f(x;\theta)$，并且学习参数$\theta$，使它能够得到最佳的函数近似。

前馈的意思是模型中数据的流动是正向的没有反馈，概念相对于包含反馈连接的循环神经网络。

网络的意思是该模型可以被表示为一个由函数组成的有向无环图。

前馈网络的最后一层被称为输出层。训练数据为我们提供了在不同训练点上取值的、含有噪声的$f^*(x)$的近似实例。训练数据只给出了最后一层函数的输出应该是什么，却没有说明其他层的函数应该怎么做，学习算法必须决定如何使用这些层来取得想要的输出。

这些网络被称为神经网络是因为它们受到了神经科学的启发。我们除了把每层想象成向量到向量的单个函数，也可以想象成许多并行操作的单元。每个单元接收一个向量，并给出一个标量，类似一个神经元的作用。然而现代神经网络研究更多是受到来自**数学和工程学科的指引**，而且目标也不是完美地给大脑建模，只是偶尔从我们了解的大脑中获得灵感。

线性模型可以被高效地拟合，但是无法理解两个输入变量的相互作用。我们从线性模型出发，思考如何突破它的局限性。我们可以不把线性模型作用于x本身，而是用在一个变换后的输入$\phi(x)$上。可以认为$\phi(x)$提供了一组描述$x$的特征。如何选择$\phi$：

1. 选择一个通用的$\phi$，例如无限维的$\phi$。**非常通用的特征映射通常只基于局部光滑的原则，没有将足够的先验信息进行编码来解决高级问题。**
2. 手动设计$\phi$，_也就是平常所说的特征工程_，需要特定领域的经验，而且很难迁移。*例如数字识别中，我们通过计算图片的对称性得到一个数字，作为数字识别的特征。*
3. 深度学习的策略是去学习$\phi$，

